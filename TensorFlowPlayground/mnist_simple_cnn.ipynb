{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network Example\n",
    "\n",
    "Recipe of a simple ConvNet to classify the MNIST data set\n",
    "The convnet architecture is as follows:\n",
    "\n",
    "Image -> [CONV -> RELU -> POOL] \\*2 -> [FC -> RELU] \\*1 -> OUT\n",
    "\n",
    "**Test Accuracy: 98.83%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Imports\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting mnist_dataset/train-images-idx3-ubyte.gz\n",
      "Extracting mnist_dataset/train-labels-idx1-ubyte.gz\n",
      "Extracting mnist_dataset/t10k-images-idx3-ubyte.gz\n",
      "Extracting mnist_dataset/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "### 1. Get the dataset\n",
    "mnist = input_data.read_data_sets(\"mnist_dataset/\", one_hot=True, reshape=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### 2. Pre-process the dataset\n",
    "\n",
    "### 3. Define the hyper params\n",
    "learning_rate = 5e-3\n",
    "num_steps = 500\n",
    "batch_size = 128\n",
    "test_valid_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### 4. Define the architecture of your CNN\n",
    "n_labels = 10\n",
    "\n",
    "images = tf.placeholder(tf.float32, shape=[None, 28, 28, 1])\n",
    "labels = tf.placeholder(tf.float32, shape=[None, n_labels])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "weights = {\n",
    "    'wc1': tf.Variable(tf.truncated_normal([5, 5, 1, 32])),\n",
    "    'wc2': tf.Variable(tf.truncated_normal([5, 5, 32, 64])),\n",
    "    'wd1': tf.Variable(tf.truncated_normal([7*7*64, 1024])),\n",
    "    'out': tf.Variable(tf.truncated_normal([1024, n_labels]))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'bc1': tf.Variable(tf.truncated_normal([32])),\n",
    "    'bc2': tf.Variable(tf.truncated_normal([64])),\n",
    "    'bd1': tf.Variable(tf.truncated_normal([1024])),\n",
    "    'out': tf.Variable(tf.truncated_normal([n_labels]))\n",
    "}\n",
    "\n",
    "def conv2d(input_vol, W, b, stride=1):\n",
    "    conv_layer = tf.nn.conv2d(input_vol, W, strides=[1, stride, stride, 1], padding='SAME')\n",
    "    conv_layer = tf.nn.bias_add(conv_layer, b)\n",
    "    return tf.nn.relu(conv_layer)\n",
    "\n",
    "def maxpool2d(input_vol, k=2, stride=2):\n",
    "    return tf.nn.max_pool(input_vol, ksize=[1, k, k, 1],\n",
    "                         strides=[1, stride, stride, 1],\n",
    "                         padding='SAME')\n",
    "\n",
    "def convnet(image, weights, biases, keep_prob):\n",
    "    # CONV1 [28x28x1] * 32[5x5x1] -> [28x28x32]\n",
    "    conv1 = conv2d(images, weights['wc1'], biases['bc1'])\n",
    "    # POOL1 [28x28x32] -> [14x14x32]\n",
    "    conv1 = maxpool2d(conv1)\n",
    "    \n",
    "    # CONV2 [14x14x32] * [5x5x64] -> [14x14x64]\n",
    "    conv2 = conv2d(conv1, weights['wc2'], biases['bc2'])\n",
    "    # POOL2 [14x14x64] -> [7x7x64]\n",
    "    conv2 = maxpool2d(conv2)\n",
    "    \n",
    "    # FC1 [7x7x64] -> [1024]\n",
    "    fc1 = tf.reshape(conv2, shape=[-1, weights['wd1'].get_shape().as_list()[0]])\n",
    "    fc1 = tf.matmul(fc1, weights['wd1']) + biases['bd1']\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    fc1 = tf.nn.dropout(fc1, keep_prob=keep_prob)\n",
    "    \n",
    "    # OUT\n",
    "    out = tf.matmul(fc1, weights['out']) + biases['out']\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:  0 Loss: 39456.5625 Val Acc 0.132812\n",
      "Step: 10 Loss:  6423.0010 Val Acc 0.550781\n",
      "Step: 20 Loss:  2379.5420 Val Acc 0.757812\n",
      "Step: 30 Loss:  1228.0571 Val Acc 0.851562\n",
      "Step: 40 Loss:   652.0731 Val Acc 0.882812\n",
      "Step: 50 Loss:   681.4171 Val Acc 0.898438\n",
      "Step: 60 Loss:   492.8727 Val Acc 0.898438\n",
      "Step: 70 Loss:   430.9157 Val Acc 0.914062\n",
      "Step: 80 Loss:   433.9691 Val Acc 0.921875\n",
      "Step: 90 Loss:   309.5247 Val Acc 0.917969\n",
      "Step: 100 Loss:   700.0853 Val Acc 0.917969\n",
      "Step: 110 Loss:   238.1288 Val Acc 0.929688\n",
      "Step: 120 Loss:    59.9271 Val Acc 0.945312\n",
      "Step: 130 Loss:   254.0185 Val Acc 0.949219\n",
      "Step: 140 Loss:   243.4996 Val Acc 0.929688\n",
      "Step: 150 Loss:   185.0963 Val Acc 0.941406\n",
      "Step: 160 Loss:   234.3543 Val Acc 0.933594\n",
      "Step: 170 Loss:   253.7953 Val Acc 0.941406\n",
      "Step: 180 Loss:   297.1905 Val Acc 0.941406\n",
      "Step: 190 Loss:   265.3884 Val Acc 0.945312\n",
      "Step: 200 Loss:   339.6373 Val Acc 0.945312\n",
      "Step: 210 Loss:    28.7253 Val Acc 0.945312\n",
      "Step: 220 Loss:   111.6054 Val Acc 0.945312\n",
      "Step: 230 Loss:   182.8120 Val Acc 0.945312\n",
      "Step: 240 Loss:   164.9918 Val Acc 0.953125\n",
      "Step: 250 Loss:    93.0513 Val Acc 0.941406\n",
      "Step: 260 Loss:   186.6927 Val Acc 0.953125\n",
      "Step: 270 Loss:    99.0194 Val Acc 0.949219\n",
      "Step: 280 Loss:   192.3236 Val Acc 0.953125\n",
      "Step: 290 Loss:   113.3795 Val Acc 0.949219\n",
      "Step: 300 Loss:   190.6402 Val Acc 0.945312\n",
      "Step: 310 Loss:    64.3766 Val Acc 0.949219\n",
      "Step: 320 Loss:   113.1432 Val Acc 0.941406\n",
      "Step: 330 Loss:    27.2955 Val Acc 0.945312\n",
      "Step: 340 Loss:   125.5982 Val Acc 0.957031\n",
      "Step: 350 Loss:    62.5308 Val Acc 0.953125\n",
      "Step: 360 Loss:     7.4775 Val Acc 0.941406\n",
      "Step: 370 Loss:    30.4013 Val Acc 0.953125\n",
      "Step: 380 Loss:    87.7892 Val Acc 0.953125\n",
      "Step: 390 Loss:   111.8597 Val Acc 0.957031\n",
      "Step: 400 Loss:    22.0532 Val Acc 0.957031\n",
      "Step: 410 Loss:     7.1468 Val Acc 0.949219\n",
      "Step: 420 Loss:    39.7483 Val Acc 0.945312\n",
      "Step: 430 Loss:    86.9996 Val Acc 0.941406\n",
      "Step: 440 Loss:   119.8291 Val Acc 0.945312\n",
      "Step: 450 Loss:    88.8815 Val Acc 0.953125\n",
      "Step: 460 Loss:    83.1250 Val Acc 0.949219\n",
      "Step: 470 Loss:    77.8604 Val Acc 0.941406\n",
      "Step: 480 Loss:   219.8761 Val Acc 0.941406\n",
      "Step: 490 Loss:    30.9010 Val Acc 0.949219\n",
      "Testing Accuracy: 0.9883\n"
     ]
    }
   ],
   "source": [
    "### 5. Run the training session and track the loss & validation accuracy\n",
    "logits = convnet(images, weights, biases, keep_prob)\n",
    "\n",
    "# Define the loss and the optimisation function\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "            logits=logits, labels=labels))\n",
    "optimiser = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_predictions = tf.equal(tf.argmax(logits, axis=1), tf.argmax(labels, axis=1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_predictions, tf.float32))\n",
    "\n",
    "# Run the graph\n",
    "with tf.Session() as session:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step_i in range(num_steps):\n",
    "        batch = mnist.train.next_batch(batch_size)\n",
    "        session.run(optimiser,\n",
    "                   feed_dict={\n",
    "                       images: batch[0],\n",
    "                       labels: batch[1],\n",
    "                       keep_prob: 0.75\n",
    "                   })\n",
    "\n",
    "        # Calculate the batch loss and validation accuracy\n",
    "        if step_i % 10 == 0: \n",
    "            loss = session.run(cost, feed_dict={\n",
    "                images: batch[0],\n",
    "                labels: batch[1],\n",
    "                keep_prob: 1.\n",
    "            })\n",
    "\n",
    "            acc = session.run(accuracy, feed_dict={\n",
    "                images: mnist.validation.images[:test_valid_size],\n",
    "                labels: mnist.validation.labels[:test_valid_size],\n",
    "                keep_prob: 1.\n",
    "            })\n",
    "\n",
    "            print('Step: {:>2} '\n",
    "                  'Loss: {:>10.4f} Val Acc {:.6f}'.format(\n",
    "                step_i, loss, acc))\n",
    "            \n",
    "    # 6. Calculate the test accuracy\n",
    "    test_acc = session.run(accuracy, feed_dict={\n",
    "        images: mnist.test.images[:test_valid_size],\n",
    "        labels: mnist.test.labels[:test_valid_size],\n",
    "        keep_prob: 1.\n",
    "    })\n",
    "    print('Testing Accuracy: {:.4f}'.format(test_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
